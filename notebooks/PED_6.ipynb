{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# YouTube trending videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(\"..\")\n",
    "\n",
    "from numpy import nan\n",
    "%matplotlib inline\n",
    "import random\n",
    "import xgboost as xgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score, plot_roc_curve, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from helpers.files import load_csv\n",
    "\n",
    "plt.rcParams[\"figure.facecolor\"] = \"#a9a9a9\"\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "def print_stats(clf, x_train, y_train, x_test, y_test):\n",
    "    y_train_pred = clf.predict(x_train)\n",
    "    print(f\"Train accuracy: {accuracy_score(y_train, y_train_pred)}\")\n",
    "    print(f\"Train precision: {precision_score(y_train, y_train_pred)}\")\n",
    "    print(f\"Train recall: {recall_score(y_train, y_train_pred)}\")\n",
    "    print(f\"Train F1: {f1_score(y_train, y_train_pred)}\\n\")\n",
    "    ax = plt.gca()\n",
    "    plot_roc_curve(clf, x_train, y_train, name=\"Train\", ax=ax)\n",
    "\n",
    "    y_test_pred = clf.predict(x_test)\n",
    "    print(f\"Test accuracy: {accuracy_score(y_test, y_test_pred)}\")\n",
    "    print(f\"Test precision: {precision_score(y_test, y_test_pred)}\")\n",
    "    print(f\"Test recall: {recall_score(y_test, y_test_pred)}\")\n",
    "    print(f\"Test F1: {f1_score(y_test, y_test_pred)}\\n\")\n",
    "    plot_roc_curve(clf, x_test, y_test, name=\"Test\", ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "load_filtered = True\n",
    "if load_filtered:\n",
    "    videos = load_csv(\"ped6_filtered_data\")[0]\n",
    "else:\n",
    "    videos = load_csv(\"ped6_data\")[0]\n",
    "\n",
    "videos = videos.sample(frac=1).reset_index(drop=True)\n",
    "videos.head(5)\n",
    "print(len(videos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y = videos[\"trending\"]\n",
    "plt.hist(y)\n",
    "x = videos.loc[:, videos.columns != \"trending\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.2, random_state=0)\n",
    "\n",
    "x_train_stats = x_train.mean()\n",
    "\n",
    "x_train = x_train.fillna(x_train_stats)\n",
    "x_test = x_test.fillna(x_train_stats)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_train = pd.DataFrame(scaler.fit_transform(x_train), columns=x.columns)\n",
    "x_test = pd.DataFrame(scaler.transform(x_test), columns=x.columns)\n",
    "\n",
    "print(f\"Train: {x_train.shape}\")\n",
    "print(f\"Test: {x_test.shape}\")\n",
    "x_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Wybór miar oceny klasyfikatorów\n",
    "\n",
    "Accuracy\n",
    "TODO wyjaśnij wybór.\n",
    "\n",
    "### Wybór pierwszego klasyfikatora\n",
    "\n",
    "RandomForest\n",
    "TODO uzasadnij wybór."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"reduce_dim__k\": [5, 10, 20, 25, 30],  # range(1, 50, 5),\n",
    "    \"classifier__max_depth\": [4, 8, 10],\n",
    "    \"classifier__min_samples_leaf\": [1, 2],  # 2, 4],\n",
    "    \"classifier__n_estimators\": [10, 50, 100, 200]\n",
    "\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"reduce_dim\", SelectKBest(chi2)),\n",
    "    (\"classifier\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, n_jobs=8, param_grid=param_grid, cv=10, verbose=1, scoring=\"f1\")\n",
    "grid_search.fit(x_train, y_train)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "### Uczenie pierwszego klasyfikatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "k = grid_search.best_params_[\"reduce_dim__k\"]\n",
    "max_depth = grid_search.best_params_[\"classifier__max_depth\"]\n",
    "min_samples_leaf = grid_search.best_params_[\"classifier__min_samples_leaf\"]\n",
    "n_estimators = grid_search.best_params_[\"classifier__n_estimators\"]\n",
    "# Tree on Random Forest\n",
    "select = SelectKBest(chi2, k=k)\n",
    "\n",
    "x_train_selected = select.fit_transform(x_train, y_train)\n",
    "x_test_selected = select.transform(x_test)\n",
    "\n",
    "mask = select.get_support()\n",
    "new_features = [feature for supported, feature in zip(mask, x.columns.values) if supported]\n",
    "\n",
    "x_train_selected = pd.DataFrame(x_train_selected, columns=new_features)\n",
    "x_test_selected = pd.DataFrame(x_test_selected, columns=new_features)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    max_depth=max_depth,\n",
    "    min_samples_leaf=min_samples_leaf\n",
    ")\n",
    "rf.fit(x_train_selected, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Testowanie pierwszego klasyfikatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_stats(rf, x_train_selected, y_train, x_test_selected, y_test)\n",
    "rf_pred = lambda x: rf.predict_proba(x).astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Interpretacja predykcji pierwszego klasyfikatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "explainerRF = shap.TreeExplainer(rf)\n",
    "\n",
    "shap_values_RF_test = explainerRF.shap_values(x_test_selected, approximate=True)\n",
    "shap_values_RF_train = explainerRF.shap_values(x_train_selected, approximate=True)\n",
    "# Random Forest\n",
    "#TODO check index\n",
    "# df_shap_RF_test = pd.DataFrame(shap_values_RF_test[1], columns=x_test.columns.values)\n",
    "# df_shap_RF_train = pd.DataFrame(shap_values_RF_train[1], columns=x_train.columns.values)\n",
    "\n",
    "# LIME has one explainer for all models\n",
    "explainer = LimeTabularExplainer(\n",
    "    x_train_selected.values,\n",
    "    feature_names=x_train_selected.columns.values.tolist(),\n",
    "    training_labels=[0, 1],\n",
    "    class_names=['Non trending', \"Trending\"],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "j = 0\n",
    "\n",
    "exp = explainer.explain_instance(x_test_selected.loc[[j]].values[0], rf_pred)\n",
    "exp.save_to_file(\"lime.html\")\n",
    "# exp.show_in_notebook(show_table=True)\n",
    "fig = exp.as_pyplot_figure()\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "j = 123\n",
    "x_test_selected.loc[[j]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# shap.force_plot(explainerRF.expected_value, shap_values_RF_test[j], x_test.iloc[[j]])\n",
    "print(y_test.to_numpy()[j])\n",
    "shap_val = explainerRF.shap_values(x_test_selected.loc[[j]], approximate=True)\n",
    "print(np.array(shap_val).shape)\n",
    "# initialize js for SHAP\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(explainerRF.expected_value[1], shap_val[1], x_test_selected.loc[[j]])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "j = 2000\n",
    "x_test_selected.loc[[j]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(y_test.to_numpy()[j])\n",
    "# shap.force_plot(explainerRF.expected_value, shap_values_RF_test[j], x_test.iloc[[j]])\n",
    "shap_val = explainerRF.shap_values(x_test_selected.loc[[j]], approximate=True)\n",
    "print(np.array(shap_val).shape)\n",
    "# initialize js for SHAP\n",
    "shap.initjs()\n",
    "shap.force_plot(explainerRF.expected_value[1], shap_val[1], x_test_selected.loc[[j]])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_val, x_test_selected.loc[[j]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Interpretacja treningowych danych"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values_RF_train[1], x_train_selected)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Interpretacja testowych danych"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values_RF_test[1], x_test_selected)\n",
    "\n",
    "# TODO pomyśl o filtrowaniu danych\n",
    "# TODO pomyśl o odfiltrowaniu innych języków"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Wybór drugiego klasyfikatora\n",
    "\n",
    "Jako drugi klasyfikator został wybrany XGBoost, ponieważ jest znany z tego że osiąga dobre wyniki (nawet na niezbalansowanych danych) jak i bardzo dobrze wyjaśnialny, poprzez to że w swojej mechanice ma zawarte ważności cech oraz prez zastosowanie boostingu oraz regularyzacji wewnątrz modelu.\n",
    "\n",
    "### Testowanie klasyfikatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgbclf_base = xgb.XGBClassifier(n_estimators=1000, use_label_encoder=False, verbosity=0)\n",
    "\n",
    "print(xgbclf_base.fit(x_train, y_train))\n",
    "\n",
    "y_pred = xgbclf_base.predict(x_test)\n",
    "print(classification_report(y_test, y_pred, target_names=['trending', 'non-trending']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Uczenie drugiego klasyfikatora\n",
    "\n",
    "**Selekcja cech**\n",
    "\n",
    "Selekcja cech została przeporwadzona poprzez analizę upadku trafności wraz z ograniczaniem liczby cech modelu"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "thresholds = sorted(xgbclf_base.feature_importances_)\n",
    "\n",
    "selection_model = xgb.XGBClassifier(n_estimators=10, use_label_encoder=False, verbosity=0)\n",
    "selection_model.fit(x_train, y_train)\n",
    "print(\"Base accuracy: %.2f%%\" % (accuracy_score(y_test, selection_model.predict(x_test)) * 100))\n",
    "\n",
    "for thresh in thresholds:\n",
    "    selection = SelectFromModel(xgbclf_base, threshold=thresh, prefit=True)\n",
    "    select_x_train = selection.transform(x_train)\n",
    "    selection_model = xgb.XGBClassifier(n_estimators=10, use_label_encoder=False, verbosity=0)\n",
    "    selection_model.fit(select_x_train, y_train)\n",
    "    select_x_test = selection.transform(x_test)\n",
    "    y_pred = selection_model.predict(select_x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_x_train.shape[1], accuracy * 100.0), accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jak rozsądną wartość ilość cech została ograniczona do 51\n",
    "\n",
    "### Interpretacja predykcji"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "thresh = thresholds[-51]\n",
    "selection = SelectFromModel(xgbclf_base, threshold=thresh, prefit=True)\n",
    "x_train_selected = selection.transform(x_train)\n",
    "\n",
    "selection_model = xgb.XGBClassifier(n_estimators=10, use_label_encoder=False, verbose=0)\n",
    "selection_model.fit(x_train_selected, y_train)\n",
    "\n",
    "x_test_selected = selection.transform(x_test)\n",
    "y_pred = selection_model.predict(x_test_selected)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, x_train_selected.shape[1], accuracy * 100.0))\n",
    "\n",
    "mask = selection.get_support()\n",
    "new_features = [feature for supported, feature in zip(mask, x.columns.values) if supported]\n",
    "\n",
    "x_train_selected = pd.DataFrame(x_train_selected, columns=new_features)\n",
    "x_test_selected = pd.DataFrame(x_test_selected, columns=new_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Strojenie parametrów**\n",
    "\n",
    "Strojenie odbywa się na modelu o mniejszej ilości estymatorów (ze względu na czas obliczeń)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "params = {\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'gamma': [0, 2, 5],\n",
    "    'max_depth': [3, 6, 9, 15]\n",
    "}\n",
    "xgbclf_par = xgb.XGBClassifier(n_estimators=10, use_label_encoder=False, nthread=1, verbosity=0)\n",
    "grid_search = GridSearchCV(xgbclf_par, n_jobs=8, param_grid=params, cv=3, verbose=1)\n",
    "grid_search.fit(x_train_selected, y_train)\n",
    "print(grid_search.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(grid_search.cv_results_['mean_test_score'])\n",
    "print(grid_search.best_score_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Uczenie drugiego klasyfikatora"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "min_child_weight = grid_search.best_params_[\"min_child_weight\"]\n",
    "max_depth = grid_search.best_params_[\"max_depth\"]\n",
    "gamma = grid_search.best_params_[\"gamma\"]\n",
    "\n",
    "xgbclf = xgb.XGBClassifier(n_estimators=1000, use_label_encoder=False, nthread=-1, verbosity=0,\n",
    "                           objective='binary:logistic',\n",
    "                           min_child_weight=min_child_weight,\n",
    "                           max_depth=max_depth,\n",
    "                           gamma=gamma)\n",
    "\n",
    "xgbclf.fit(x_train_selected, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print_stats(xgbclf, x_train_selected, y_train, x_test_selected, y_test)\n",
    "y_pred = xgbclf.predict(x_test_selected)\n",
    "print(\"Test results: \\n\", classification_report(y_test, y_pred, target_names=['trending', 'non-trending']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ważność atrybutów wg. weight pokazuje jak często w drzewach pojawiają się dane cechy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "xgb.plot_importance(xgbclf, max_num_features=50, height=0.5, ax=ax, importance_type='weight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ważność atrybutów wg. gain ozancza jak dużą część trafności wnosi dana cecha"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "xgb.plot_importance(xgbclf, max_num_features=50, height=0.5, ax=ax, importance_type='gain')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "xgb.plot_importance(xgbclf, max_num_features=50, height=0.5, ax=ax, importance_type='gain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbclf_base = xgb.XGBClassifier(n_estimators=10, use_label_encoder=False, verbosity=0)\n",
    "\n",
    "print(xgbclf_base.fit(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] =  [500, 500]\n",
    "xgb.plot_tree(xgbclf_base,num_trees=0)\n",
    "plt.show()\n",
    "\n",
    "# fig = plt.gcf()\n",
    "# fig.set_size_inches(1000, 500)\n",
    "# fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SHAP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8, 6]\n",
    "xgb_pred = lambda x: xgbclf.predict_proba(x).astype(float)\n",
    "\n",
    "# LIME has one explainer for all models,\n",
    "\n",
    "explainer = LimeTabularExplainer(\n",
    "    x_train_selected.values,\n",
    "    feature_names=x_train.columns.values.tolist(),\n",
    "    training_labels=[0, 1],\n",
    "    class_names=['Non trending', \"Trending\"],\n",
    "    verbose=True)\n",
    "\n",
    "j = 0\n",
    "\n",
    "exp = explainer.explain_instance(x_test_selected.loc[[j]].values[0], xgb_pred)\n",
    "exp.save_to_file(\"lime2.html\")\n",
    "# exp.show_in_notebook(show_table=True),\n",
    "fig = exp.as_pyplot_figure()\n",
    "plt.show(fig)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_sampled = x_test_selected.sample(100, random_state=0)\n",
    "explainerXgb = shap.TreeExplainer(xgbclf)\n",
    "shap_values = explainerXgb.shap_values(x_sampled)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "shap.force_plot(explainerXgb.expected_value, shap_values[1], x_sampled.iloc[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "shap_values = explainerXgb.shap_values(x_train_selected)\n",
    "shap.force_plot(explainerXgb.expected_value, shap_values[1], x_train_selected.iloc[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shap_values = explainerXgb.shap_values(x_sampled)\n",
    "shap.summary_plot(shap_values, x_sampled)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "shap.summary_plot(shap_values, x_sampled, plot_type=\"bar\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testowanie drugiego klasyfikatora\n",
    "\n",
    "### Interpretacja predykcji drugiego klasyfikatora\n",
    "\n",
    "### Porównanie wyników klasyfikatorów\n",
    "\n",
    "### Wiedza dla klienta\n",
    "\n",
    "Profil charakterystycznych wartości atrybutów dla klasy trending\n",
    "\n",
    "Co trzeba robić?\n",
    "\n",
    "Czego się wystrzegać?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('ml': virtualenvwrapper)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "258d9c3fe2c2041f692db8763ec1691cd73586bc3236962ad99db3f9aaf4b0b7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}